# ğŸš€ 14-Day AI Challenge â€” Ecommerce Behavior Analytics

**Organizers:** Databricks, CodeBasics, Indian Data Club  
**Challenge Duration:** Feb 20 â€“ Mar 5  
**Goal:** Build a scalable AI and Data Engineering pipeline using Spark, Databricks, and large-scale ecommerce datasets.

---

## ğŸ§  Challenge Objective

The goal of this challenge is to:

- Ingest and process large-scale ecommerce datasets (~1.1GB)  
- Enforce schema in Spark for production-grade reliability  
- Perform exploratory data analysis (EDA) and data quality checks  
- Build event funnels and user behavior insights  
- Optimize data pipelines using Databricks best practices  

This project is part of my **learning journey and portfolio-building exercise** in Data Engineering & AI.

---

## ğŸ“‚ Dataset

- **Source:** Kaggle â€“ Ecommerce Behavior Data from Multi-Category Store  
- **File Used:** `2019-Oct.csv` (~1.1GB)  
- **Event Types:** `view`, `cart`, `purchase`, `remove_from_cart`  

| Column | Type | Description |
|--------|------|------------|
| event_time | timestamp | When the event happened (UTC) |
| event_type | string | Type of user interaction |
| product_id | long | Unique product identifier |
| category_id | long | Category identifier |
| category_code | string | Product category hierarchy |
| brand | string | Product brand |
| price | double | Product price in USD |
| user_id | long | Permanent user identifier |
| user_session | string | Session identifier |

---

## ğŸ“… Challenge Timeline

- **Pre-Day / Feb 18:** Setup & prerequisites  
- **Day 1 (Feb 20):** Data understanding & quality analysis  
- **Day 2 (Feb 21):** Event funnel & user behavior  
- **Day 3-6 (Feb 22â€“25):** Feature engineering & optimization  
- **Day 7-10 (Feb 26â€“Mar 1):** Advanced analytics  
- **Day 11-14 (Mar 2â€“5):** Reporting, dashboards & documentation  

> Each day will have a detailed **daily log README** to track learning and progress.

---

## ğŸ› ï¸ Tech Stack

- Apache Spark (PySpark)  
- Databricks  
- Unity Catalog Volumes  
- Python  
- Kaggle CLI  

---

## ğŸ¯ Learning Goals

- Handle GB-scale datasets efficiently  
- Production-grade schema enforcement in Spark  
- Scalable data pipelines & optimizations  
- Event funnel & session-level metrics  
- Portfolio-ready AI + Data Engineering project  

---

## ğŸ‘©â€ğŸ’» Author

Vidyullatha Polavarapu
Data Engineer / AI Enthusiast  
#14DayAIChallenge#DatabrickswithIDC#codebasics#indiandataclub#databricks
